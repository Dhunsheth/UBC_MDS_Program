{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbors (KNN) Classification\n",
    "1. Initialize K value. K is the number of nearest neighbors to consider and it controls the balance between overfitting and underfitting. [1 point]\n",
    "\n",
    "2. Prepare the training data. [1 point]\n",
    "\n",
    "3.  For each example in the test set\n",
    "\n",
    "    3.1 Calculate the Euclidean distance between the training set examples (X_train) and the current example from the test data set. [1 point]\n",
    "\n",
    "    3.2 Sort the distances in ascending order and get the K nearest neighbors based on the calculated distances. [1 point]\n",
    "\n",
    "    3.3 Get the labels of the K nearest neighbors. [1 point]\n",
    "\n",
    "    3.4 Get the most common label using [np.unique with return_counts=True and np.argmax] or scipy.stats.mode. [2 points]\n",
    "\n",
    "    3.5 Append the predicted label to the output list. [1 point]\n",
    "\n",
    "4. Verify your classifier and fine tune it (change K values to see the change in accuracy) using the Breast Cancer dataset. [1 point for fine-tuning and discussion, and 1 point for successful running of the model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class KNNClassifier:\n",
    "    def __init__(self, k=3):\n",
    "        # 1. Initialize the number of neighbors K. [1 point]\n",
    "        \"YOUR CODE\"\n",
    "        self.k=k\n",
    "\n",
    "    def fit(self, X_train, y_train):\n",
    "        # 2. Prepare the training data [1 point]\n",
    "        \"YOUR CODE\"\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        # batch prediction\n",
    "        predictions = []\n",
    "\n",
    "        # 3. loop over all samples in the test set\n",
    "        for sample in X_test:\n",
    "            \n",
    "            # 3.1 Compute the distance between the test sample and all training samples in X-train, use np.linalg.norm  [1 point]\n",
    "            \"YOUR CODE\"\n",
    "            distances = np.linalg.norm(sample - self.X_train, axis=1)\n",
    "\n",
    "            # 3.2 Sort the distances and return the indices of K nearest neighbors using np.argsort [1 point]\n",
    "            \"YOUR CODE\"\n",
    "            nearest_neighbors_indices = np.argsort(distances)[:self.k]\n",
    "\n",
    "            # 3.3 Get the labels of the K nearest neighbors [1 point]\n",
    "            \"YOUR CODE\"\n",
    "            nearest_labels = self.y_train[nearest_neighbors_indices]\n",
    "\n",
    "            # 3.4 Get the most common label using [np.unique with return_counts=True and np.argmax] or scipy.stats.mode [2 points]\n",
    "            \"YOUR CODE\"\n",
    "            unique_vals = np.unique(nearest_labels, return_counts=True)\n",
    "            predicted_label = unique_vals[0][np.argmax(unique_vals[1])]\n",
    "            \n",
    "            # 3.5 Append the predicted label to the output [1 point]\n",
    "            \"YOUR CODE\"\n",
    "            predictions.append(predicted_label)\n",
    "\n",
    "        #return the predictions of all test samples\n",
    "        return np.array(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9298245614035088\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "breast_cancer = load_breast_cancer()\n",
    "X = breast_cancer.data\n",
    "y = breast_cancer.target\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create and train the KNN classifier\n",
    "knn_classifier = KNNClassifier(k=3)\n",
    "knn_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "predictions = knn_classifier.predict(X_test)\n",
    "\n",
    "# Calculate accuracy [1 point for good accuracy]\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Remember you need to fine tune your classifier (change K values to see the change in accuracy). \n",
    "# 1 point will be given for fine-tuning and a brief discussion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fine-tuning K**\n",
    "\n",
    "I will fine tune K by running a simulation which tests different values of K and compares the resulting accuracy, to pick the best K. I loop through choosing K from 1 to all observations in the training set and graph the results below. It is found a K of 10 leads to the best accuracy (about 98.2%), as shown in the below analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-4ed8d4c3055f4192b92eab5e7cf4fc30.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-4ed8d4c3055f4192b92eab5e7cf4fc30.vega-embed details,\n",
       "  #altair-viz-4ed8d4c3055f4192b92eab5e7cf4fc30.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-4ed8d4c3055f4192b92eab5e7cf4fc30\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-4ed8d4c3055f4192b92eab5e7cf4fc30\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-4ed8d4c3055f4192b92eab5e7cf4fc30\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.16.3?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.16.3\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-9cd338ab7c4e3dd94a51cb734d313d09\"}, \"mark\": {\"type\": \"line\"}, \"encoding\": {\"x\": {\"field\": \"index\", \"title\": \"Choice of K\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"accuracy\", \"title\": \"Values\", \"type\": \"quantitative\"}}, \"height\": 500, \"width\": 800, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.16.3.json\", \"datasets\": {\"data-9cd338ab7c4e3dd94a51cb734d313d09\": [{\"index\": 1, \"accuracy\": 0.9298245614035088}, {\"index\": 2, \"accuracy\": 0.9298245614035088}, {\"index\": 3, \"accuracy\": 0.9298245614035088}, {\"index\": 4, \"accuracy\": 0.9385964912280702}, {\"index\": 5, \"accuracy\": 0.956140350877193}, {\"index\": 6, \"accuracy\": 0.9649122807017544}, {\"index\": 7, \"accuracy\": 0.956140350877193}, {\"index\": 8, \"accuracy\": 0.956140350877193}, {\"index\": 9, \"accuracy\": 0.956140350877193}, {\"index\": 10, \"accuracy\": 0.9736842105263158}, {\"index\": 11, \"accuracy\": 0.9824561403508771}, {\"index\": 12, \"accuracy\": 0.9824561403508771}, {\"index\": 13, \"accuracy\": 0.9736842105263158}, {\"index\": 14, \"accuracy\": 0.9736842105263158}, {\"index\": 15, \"accuracy\": 0.9649122807017544}, {\"index\": 16, \"accuracy\": 0.9649122807017544}, {\"index\": 17, \"accuracy\": 0.9649122807017544}, {\"index\": 18, \"accuracy\": 0.9649122807017544}, {\"index\": 19, \"accuracy\": 0.9649122807017544}, {\"index\": 20, \"accuracy\": 0.9649122807017544}, {\"index\": 21, \"accuracy\": 0.9649122807017544}, {\"index\": 22, \"accuracy\": 0.9649122807017544}, {\"index\": 23, \"accuracy\": 0.956140350877193}, {\"index\": 24, \"accuracy\": 0.9649122807017544}, {\"index\": 25, \"accuracy\": 0.9473684210526315}, {\"index\": 26, \"accuracy\": 0.9473684210526315}, {\"index\": 27, \"accuracy\": 0.9473684210526315}, {\"index\": 28, \"accuracy\": 0.9473684210526315}, {\"index\": 29, \"accuracy\": 0.9473684210526315}, {\"index\": 30, \"accuracy\": 0.9473684210526315}, {\"index\": 31, \"accuracy\": 0.9473684210526315}, {\"index\": 32, \"accuracy\": 0.9473684210526315}, {\"index\": 33, \"accuracy\": 0.9473684210526315}, {\"index\": 34, \"accuracy\": 0.9473684210526315}, {\"index\": 35, \"accuracy\": 0.9473684210526315}, {\"index\": 36, \"accuracy\": 0.9473684210526315}, {\"index\": 37, \"accuracy\": 0.9473684210526315}, {\"index\": 38, \"accuracy\": 0.9473684210526315}, {\"index\": 39, \"accuracy\": 0.9473684210526315}, {\"index\": 40, \"accuracy\": 0.9473684210526315}, {\"index\": 41, \"accuracy\": 0.9473684210526315}, {\"index\": 42, \"accuracy\": 0.9473684210526315}, {\"index\": 43, \"accuracy\": 0.9473684210526315}, {\"index\": 44, \"accuracy\": 0.9473684210526315}, {\"index\": 45, \"accuracy\": 0.9473684210526315}, {\"index\": 46, \"accuracy\": 0.9473684210526315}, {\"index\": 47, \"accuracy\": 0.9473684210526315}, {\"index\": 48, \"accuracy\": 0.9473684210526315}, {\"index\": 49, \"accuracy\": 0.9473684210526315}, {\"index\": 50, \"accuracy\": 0.9473684210526315}, {\"index\": 51, \"accuracy\": 0.9473684210526315}, {\"index\": 52, \"accuracy\": 0.9473684210526315}, {\"index\": 53, \"accuracy\": 0.9473684210526315}, {\"index\": 54, \"accuracy\": 0.9473684210526315}, {\"index\": 55, \"accuracy\": 0.9473684210526315}, {\"index\": 56, \"accuracy\": 0.9473684210526315}, {\"index\": 57, \"accuracy\": 0.9473684210526315}, {\"index\": 58, \"accuracy\": 0.9473684210526315}, {\"index\": 59, \"accuracy\": 0.9473684210526315}, {\"index\": 60, \"accuracy\": 0.9473684210526315}, {\"index\": 61, \"accuracy\": 0.9473684210526315}, {\"index\": 62, \"accuracy\": 0.9473684210526315}, {\"index\": 63, \"accuracy\": 0.9473684210526315}, {\"index\": 64, \"accuracy\": 0.9473684210526315}, {\"index\": 65, \"accuracy\": 0.9473684210526315}, {\"index\": 66, \"accuracy\": 0.9473684210526315}, {\"index\": 67, \"accuracy\": 0.9473684210526315}, {\"index\": 68, \"accuracy\": 0.9473684210526315}, {\"index\": 69, \"accuracy\": 0.9473684210526315}, {\"index\": 70, \"accuracy\": 0.9473684210526315}, {\"index\": 71, \"accuracy\": 0.9473684210526315}, {\"index\": 72, \"accuracy\": 0.9473684210526315}, {\"index\": 73, \"accuracy\": 0.9473684210526315}, {\"index\": 74, \"accuracy\": 0.9473684210526315}, {\"index\": 75, \"accuracy\": 0.9473684210526315}, {\"index\": 76, \"accuracy\": 0.9473684210526315}, {\"index\": 77, \"accuracy\": 0.9473684210526315}, {\"index\": 78, \"accuracy\": 0.9473684210526315}, {\"index\": 79, \"accuracy\": 0.9473684210526315}, {\"index\": 80, \"accuracy\": 0.9473684210526315}, {\"index\": 81, \"accuracy\": 0.9473684210526315}, {\"index\": 82, \"accuracy\": 0.9473684210526315}, {\"index\": 83, \"accuracy\": 0.9473684210526315}, {\"index\": 84, \"accuracy\": 0.9473684210526315}, {\"index\": 85, \"accuracy\": 0.9473684210526315}, {\"index\": 86, \"accuracy\": 0.9473684210526315}, {\"index\": 87, \"accuracy\": 0.9473684210526315}, {\"index\": 88, \"accuracy\": 0.9473684210526315}, {\"index\": 89, \"accuracy\": 0.9473684210526315}, {\"index\": 90, \"accuracy\": 0.9473684210526315}, {\"index\": 91, \"accuracy\": 0.9473684210526315}, {\"index\": 92, \"accuracy\": 0.9473684210526315}, {\"index\": 93, \"accuracy\": 0.9473684210526315}, {\"index\": 94, \"accuracy\": 0.9473684210526315}, {\"index\": 95, \"accuracy\": 0.9473684210526315}, {\"index\": 96, \"accuracy\": 0.9473684210526315}, {\"index\": 97, \"accuracy\": 0.9473684210526315}, {\"index\": 98, \"accuracy\": 0.9473684210526315}, {\"index\": 99, \"accuracy\": 0.9473684210526315}, {\"index\": 100, \"accuracy\": 0.9473684210526315}, {\"index\": 101, \"accuracy\": 0.9473684210526315}, {\"index\": 102, \"accuracy\": 0.9473684210526315}, {\"index\": 103, \"accuracy\": 0.9473684210526315}, {\"index\": 104, \"accuracy\": 0.9473684210526315}, {\"index\": 105, \"accuracy\": 0.9473684210526315}, {\"index\": 106, \"accuracy\": 0.9473684210526315}, {\"index\": 107, \"accuracy\": 0.9473684210526315}, {\"index\": 108, \"accuracy\": 0.9473684210526315}, {\"index\": 109, \"accuracy\": 0.9473684210526315}, {\"index\": 110, \"accuracy\": 0.9473684210526315}, {\"index\": 111, \"accuracy\": 0.9473684210526315}, {\"index\": 112, \"accuracy\": 0.9473684210526315}, {\"index\": 113, \"accuracy\": 0.9385964912280702}, {\"index\": 114, \"accuracy\": 0.9473684210526315}, {\"index\": 115, \"accuracy\": 0.9473684210526315}, {\"index\": 116, \"accuracy\": 0.9473684210526315}, {\"index\": 117, \"accuracy\": 0.9385964912280702}, {\"index\": 118, \"accuracy\": 0.9473684210526315}, {\"index\": 119, \"accuracy\": 0.9385964912280702}, {\"index\": 120, \"accuracy\": 0.9385964912280702}, {\"index\": 121, \"accuracy\": 0.9385964912280702}, {\"index\": 122, \"accuracy\": 0.9385964912280702}, {\"index\": 123, \"accuracy\": 0.9385964912280702}, {\"index\": 124, \"accuracy\": 0.9385964912280702}, {\"index\": 125, \"accuracy\": 0.9385964912280702}, {\"index\": 126, \"accuracy\": 0.9385964912280702}, {\"index\": 127, \"accuracy\": 0.9385964912280702}, {\"index\": 128, \"accuracy\": 0.9385964912280702}, {\"index\": 129, \"accuracy\": 0.9385964912280702}, {\"index\": 130, \"accuracy\": 0.9385964912280702}, {\"index\": 131, \"accuracy\": 0.9385964912280702}, {\"index\": 132, \"accuracy\": 0.9385964912280702}, {\"index\": 133, \"accuracy\": 0.9385964912280702}, {\"index\": 134, \"accuracy\": 0.9385964912280702}, {\"index\": 135, \"accuracy\": 0.9385964912280702}, {\"index\": 136, \"accuracy\": 0.9385964912280702}, {\"index\": 137, \"accuracy\": 0.9385964912280702}, {\"index\": 138, \"accuracy\": 0.9385964912280702}, {\"index\": 139, \"accuracy\": 0.9385964912280702}, {\"index\": 140, \"accuracy\": 0.9385964912280702}, {\"index\": 141, \"accuracy\": 0.9385964912280702}, {\"index\": 142, \"accuracy\": 0.9385964912280702}, {\"index\": 143, \"accuracy\": 0.9385964912280702}, {\"index\": 144, \"accuracy\": 0.9385964912280702}, {\"index\": 145, \"accuracy\": 0.9385964912280702}, {\"index\": 146, \"accuracy\": 0.9385964912280702}, {\"index\": 147, \"accuracy\": 0.9385964912280702}, {\"index\": 148, \"accuracy\": 0.9385964912280702}, {\"index\": 149, \"accuracy\": 0.9385964912280702}, {\"index\": 150, \"accuracy\": 0.9385964912280702}, {\"index\": 151, \"accuracy\": 0.9385964912280702}, {\"index\": 152, \"accuracy\": 0.9385964912280702}, {\"index\": 153, \"accuracy\": 0.9385964912280702}, {\"index\": 154, \"accuracy\": 0.9385964912280702}, {\"index\": 155, \"accuracy\": 0.9385964912280702}, {\"index\": 156, \"accuracy\": 0.9385964912280702}, {\"index\": 157, \"accuracy\": 0.9385964912280702}, {\"index\": 158, \"accuracy\": 0.9385964912280702}, {\"index\": 159, \"accuracy\": 0.9385964912280702}, {\"index\": 160, \"accuracy\": 0.9385964912280702}, {\"index\": 161, \"accuracy\": 0.9385964912280702}, {\"index\": 162, \"accuracy\": 0.9385964912280702}, {\"index\": 163, \"accuracy\": 0.9385964912280702}, {\"index\": 164, \"accuracy\": 0.9385964912280702}, {\"index\": 165, \"accuracy\": 0.9385964912280702}, {\"index\": 166, \"accuracy\": 0.9385964912280702}, {\"index\": 167, \"accuracy\": 0.9385964912280702}, {\"index\": 168, \"accuracy\": 0.9385964912280702}, {\"index\": 169, \"accuracy\": 0.9385964912280702}, {\"index\": 170, \"accuracy\": 0.9385964912280702}, {\"index\": 171, \"accuracy\": 0.9210526315789473}, {\"index\": 172, \"accuracy\": 0.9385964912280702}, {\"index\": 173, \"accuracy\": 0.9298245614035088}, {\"index\": 174, \"accuracy\": 0.9298245614035088}, {\"index\": 175, \"accuracy\": 0.9122807017543859}, {\"index\": 176, \"accuracy\": 0.9122807017543859}, {\"index\": 177, \"accuracy\": 0.9122807017543859}, {\"index\": 178, \"accuracy\": 0.9122807017543859}, {\"index\": 179, \"accuracy\": 0.9122807017543859}, {\"index\": 180, \"accuracy\": 0.9122807017543859}, {\"index\": 181, \"accuracy\": 0.9035087719298246}, {\"index\": 182, \"accuracy\": 0.9035087719298246}, {\"index\": 183, \"accuracy\": 0.9035087719298246}, {\"index\": 184, \"accuracy\": 0.9035087719298246}, {\"index\": 185, \"accuracy\": 0.9035087719298246}, {\"index\": 186, \"accuracy\": 0.9035087719298246}, {\"index\": 187, \"accuracy\": 0.9035087719298246}, {\"index\": 188, \"accuracy\": 0.9035087719298246}, {\"index\": 189, \"accuracy\": 0.9035087719298246}, {\"index\": 190, \"accuracy\": 0.9035087719298246}, {\"index\": 191, \"accuracy\": 0.9035087719298246}, {\"index\": 192, \"accuracy\": 0.9035087719298246}, {\"index\": 193, \"accuracy\": 0.9035087719298246}, {\"index\": 194, \"accuracy\": 0.9035087719298246}, {\"index\": 195, \"accuracy\": 0.9035087719298246}, {\"index\": 196, \"accuracy\": 0.9035087719298246}, {\"index\": 197, \"accuracy\": 0.9035087719298246}, {\"index\": 198, \"accuracy\": 0.9035087719298246}, {\"index\": 199, \"accuracy\": 0.9035087719298246}, {\"index\": 200, \"accuracy\": 0.9035087719298246}, {\"index\": 201, \"accuracy\": 0.9035087719298246}, {\"index\": 202, \"accuracy\": 0.9035087719298246}, {\"index\": 203, \"accuracy\": 0.9035087719298246}, {\"index\": 204, \"accuracy\": 0.9035087719298246}, {\"index\": 205, \"accuracy\": 0.9035087719298246}, {\"index\": 206, \"accuracy\": 0.9035087719298246}, {\"index\": 207, \"accuracy\": 0.9035087719298246}, {\"index\": 208, \"accuracy\": 0.9035087719298246}, {\"index\": 209, \"accuracy\": 0.9035087719298246}, {\"index\": 210, \"accuracy\": 0.9035087719298246}, {\"index\": 211, \"accuracy\": 0.9035087719298246}, {\"index\": 212, \"accuracy\": 0.9035087719298246}, {\"index\": 213, \"accuracy\": 0.9035087719298246}, {\"index\": 214, \"accuracy\": 0.9035087719298246}, {\"index\": 215, \"accuracy\": 0.9035087719298246}, {\"index\": 216, \"accuracy\": 0.9035087719298246}, {\"index\": 217, \"accuracy\": 0.9035087719298246}, {\"index\": 218, \"accuracy\": 0.9035087719298246}, {\"index\": 219, \"accuracy\": 0.9035087719298246}, {\"index\": 220, \"accuracy\": 0.9035087719298246}, {\"index\": 221, \"accuracy\": 0.9035087719298246}, {\"index\": 222, \"accuracy\": 0.9035087719298246}, {\"index\": 223, \"accuracy\": 0.9035087719298246}, {\"index\": 224, \"accuracy\": 0.9035087719298246}, {\"index\": 225, \"accuracy\": 0.8947368421052632}, {\"index\": 226, \"accuracy\": 0.9035087719298246}, {\"index\": 227, \"accuracy\": 0.8947368421052632}, {\"index\": 228, \"accuracy\": 0.9035087719298246}, {\"index\": 229, \"accuracy\": 0.8859649122807017}, {\"index\": 230, \"accuracy\": 0.8859649122807017}, {\"index\": 231, \"accuracy\": 0.8859649122807017}, {\"index\": 232, \"accuracy\": 0.8859649122807017}, {\"index\": 233, \"accuracy\": 0.8859649122807017}, {\"index\": 234, \"accuracy\": 0.8859649122807017}, {\"index\": 235, \"accuracy\": 0.8859649122807017}, {\"index\": 236, \"accuracy\": 0.8859649122807017}, {\"index\": 237, \"accuracy\": 0.8859649122807017}, {\"index\": 238, \"accuracy\": 0.8859649122807017}, {\"index\": 239, \"accuracy\": 0.8859649122807017}, {\"index\": 240, \"accuracy\": 0.8859649122807017}, {\"index\": 241, \"accuracy\": 0.8859649122807017}, {\"index\": 242, \"accuracy\": 0.8859649122807017}, {\"index\": 243, \"accuracy\": 0.8771929824561403}, {\"index\": 244, \"accuracy\": 0.8859649122807017}, {\"index\": 245, \"accuracy\": 0.8859649122807017}, {\"index\": 246, \"accuracy\": 0.8859649122807017}, {\"index\": 247, \"accuracy\": 0.8771929824561403}, {\"index\": 248, \"accuracy\": 0.8859649122807017}, {\"index\": 249, \"accuracy\": 0.8859649122807017}, {\"index\": 250, \"accuracy\": 0.8859649122807017}, {\"index\": 251, \"accuracy\": 0.8771929824561403}, {\"index\": 252, \"accuracy\": 0.8771929824561403}, {\"index\": 253, \"accuracy\": 0.8771929824561403}, {\"index\": 254, \"accuracy\": 0.8771929824561403}, {\"index\": 255, \"accuracy\": 0.8771929824561403}, {\"index\": 256, \"accuracy\": 0.8771929824561403}, {\"index\": 257, \"accuracy\": 0.8771929824561403}, {\"index\": 258, \"accuracy\": 0.8771929824561403}, {\"index\": 259, \"accuracy\": 0.8771929824561403}, {\"index\": 260, \"accuracy\": 0.8771929824561403}, {\"index\": 261, \"accuracy\": 0.8771929824561403}, {\"index\": 262, \"accuracy\": 0.8771929824561403}, {\"index\": 263, \"accuracy\": 0.868421052631579}, {\"index\": 264, \"accuracy\": 0.8771929824561403}, {\"index\": 265, \"accuracy\": 0.8596491228070176}, {\"index\": 266, \"accuracy\": 0.8596491228070176}, {\"index\": 267, \"accuracy\": 0.8508771929824561}, {\"index\": 268, \"accuracy\": 0.8508771929824561}, {\"index\": 269, \"accuracy\": 0.8508771929824561}, {\"index\": 270, \"accuracy\": 0.8508771929824561}, {\"index\": 271, \"accuracy\": 0.8508771929824561}, {\"index\": 272, \"accuracy\": 0.8508771929824561}, {\"index\": 273, \"accuracy\": 0.8508771929824561}, {\"index\": 274, \"accuracy\": 0.8508771929824561}, {\"index\": 275, \"accuracy\": 0.8508771929824561}, {\"index\": 276, \"accuracy\": 0.8508771929824561}, {\"index\": 277, \"accuracy\": 0.8508771929824561}, {\"index\": 278, \"accuracy\": 0.8508771929824561}, {\"index\": 279, \"accuracy\": 0.8508771929824561}, {\"index\": 280, \"accuracy\": 0.8508771929824561}, {\"index\": 281, \"accuracy\": 0.8421052631578947}, {\"index\": 282, \"accuracy\": 0.8421052631578947}, {\"index\": 283, \"accuracy\": 0.8421052631578947}, {\"index\": 284, \"accuracy\": 0.8421052631578947}, {\"index\": 285, \"accuracy\": 0.8421052631578947}, {\"index\": 286, \"accuracy\": 0.8421052631578947}, {\"index\": 287, \"accuracy\": 0.8245614035087719}, {\"index\": 288, \"accuracy\": 0.8245614035087719}, {\"index\": 289, \"accuracy\": 0.8245614035087719}, {\"index\": 290, \"accuracy\": 0.8245614035087719}, {\"index\": 291, \"accuracy\": 0.8157894736842105}, {\"index\": 292, \"accuracy\": 0.8157894736842105}, {\"index\": 293, \"accuracy\": 0.8157894736842105}, {\"index\": 294, \"accuracy\": 0.8157894736842105}, {\"index\": 295, \"accuracy\": 0.8157894736842105}, {\"index\": 296, \"accuracy\": 0.8157894736842105}, {\"index\": 297, \"accuracy\": 0.8157894736842105}, {\"index\": 298, \"accuracy\": 0.8157894736842105}, {\"index\": 299, \"accuracy\": 0.8070175438596491}, {\"index\": 300, \"accuracy\": 0.8070175438596491}, {\"index\": 301, \"accuracy\": 0.7894736842105263}, {\"index\": 302, \"accuracy\": 0.7894736842105263}, {\"index\": 303, \"accuracy\": 0.7807017543859649}, {\"index\": 304, \"accuracy\": 0.7807017543859649}, {\"index\": 305, \"accuracy\": 0.7719298245614035}, {\"index\": 306, \"accuracy\": 0.7719298245614035}, {\"index\": 307, \"accuracy\": 0.7719298245614035}, {\"index\": 308, \"accuracy\": 0.7719298245614035}, {\"index\": 309, \"accuracy\": 0.7719298245614035}, {\"index\": 310, \"accuracy\": 0.7719298245614035}, {\"index\": 311, \"accuracy\": 0.7719298245614035}, {\"index\": 312, \"accuracy\": 0.7719298245614035}, {\"index\": 313, \"accuracy\": 0.7719298245614035}, {\"index\": 314, \"accuracy\": 0.7719298245614035}, {\"index\": 315, \"accuracy\": 0.7719298245614035}, {\"index\": 316, \"accuracy\": 0.7719298245614035}, {\"index\": 317, \"accuracy\": 0.7719298245614035}, {\"index\": 318, \"accuracy\": 0.7719298245614035}, {\"index\": 319, \"accuracy\": 0.7368421052631579}, {\"index\": 320, \"accuracy\": 0.7368421052631579}, {\"index\": 321, \"accuracy\": 0.7280701754385965}, {\"index\": 322, \"accuracy\": 0.7280701754385965}, {\"index\": 323, \"accuracy\": 0.7280701754385965}, {\"index\": 324, \"accuracy\": 0.7280701754385965}, {\"index\": 325, \"accuracy\": 0.7192982456140351}, {\"index\": 326, \"accuracy\": 0.7192982456140351}, {\"index\": 327, \"accuracy\": 0.7017543859649122}, {\"index\": 328, \"accuracy\": 0.7017543859649122}, {\"index\": 329, \"accuracy\": 0.6842105263157895}, {\"index\": 330, \"accuracy\": 0.6842105263157895}, {\"index\": 331, \"accuracy\": 0.6842105263157895}, {\"index\": 332, \"accuracy\": 0.6842105263157895}, {\"index\": 333, \"accuracy\": 0.6491228070175439}, {\"index\": 334, \"accuracy\": 0.6491228070175439}, {\"index\": 335, \"accuracy\": 0.6228070175438597}, {\"index\": 336, \"accuracy\": 0.6228070175438597}, {\"index\": 337, \"accuracy\": 0.6228070175438597}, {\"index\": 338, \"accuracy\": 0.6228070175438597}, {\"index\": 339, \"accuracy\": 0.6228070175438597}, {\"index\": 340, \"accuracy\": 0.6228070175438597}, {\"index\": 341, \"accuracy\": 0.6228070175438597}, {\"index\": 342, \"accuracy\": 0.6228070175438597}, {\"index\": 343, \"accuracy\": 0.6228070175438597}, {\"index\": 344, \"accuracy\": 0.6228070175438597}, {\"index\": 345, \"accuracy\": 0.6228070175438597}, {\"index\": 346, \"accuracy\": 0.6228070175438597}, {\"index\": 347, \"accuracy\": 0.6228070175438597}, {\"index\": 348, \"accuracy\": 0.6228070175438597}, {\"index\": 349, \"accuracy\": 0.6228070175438597}, {\"index\": 350, \"accuracy\": 0.6228070175438597}, {\"index\": 351, \"accuracy\": 0.6228070175438597}, {\"index\": 352, \"accuracy\": 0.6228070175438597}, {\"index\": 353, \"accuracy\": 0.6228070175438597}, {\"index\": 354, \"accuracy\": 0.6228070175438597}, {\"index\": 355, \"accuracy\": 0.6228070175438597}, {\"index\": 356, \"accuracy\": 0.6228070175438597}, {\"index\": 357, \"accuracy\": 0.6228070175438597}, {\"index\": 358, \"accuracy\": 0.6228070175438597}, {\"index\": 359, \"accuracy\": 0.6228070175438597}, {\"index\": 360, \"accuracy\": 0.6228070175438597}, {\"index\": 361, \"accuracy\": 0.6228070175438597}, {\"index\": 362, \"accuracy\": 0.6228070175438597}, {\"index\": 363, \"accuracy\": 0.6228070175438597}, {\"index\": 364, \"accuracy\": 0.6228070175438597}, {\"index\": 365, \"accuracy\": 0.6228070175438597}, {\"index\": 366, \"accuracy\": 0.6228070175438597}, {\"index\": 367, \"accuracy\": 0.6228070175438597}, {\"index\": 368, \"accuracy\": 0.6228070175438597}, {\"index\": 369, \"accuracy\": 0.6228070175438597}, {\"index\": 370, \"accuracy\": 0.6228070175438597}, {\"index\": 371, \"accuracy\": 0.6228070175438597}, {\"index\": 372, \"accuracy\": 0.6228070175438597}, {\"index\": 373, \"accuracy\": 0.6228070175438597}, {\"index\": 374, \"accuracy\": 0.6228070175438597}, {\"index\": 375, \"accuracy\": 0.6228070175438597}, {\"index\": 376, \"accuracy\": 0.6228070175438597}, {\"index\": 377, \"accuracy\": 0.6228070175438597}, {\"index\": 378, \"accuracy\": 0.6228070175438597}, {\"index\": 379, \"accuracy\": 0.6228070175438597}, {\"index\": 380, \"accuracy\": 0.6228070175438597}, {\"index\": 381, \"accuracy\": 0.6228070175438597}, {\"index\": 382, \"accuracy\": 0.6228070175438597}, {\"index\": 383, \"accuracy\": 0.6228070175438597}, {\"index\": 384, \"accuracy\": 0.6228070175438597}, {\"index\": 385, \"accuracy\": 0.6228070175438597}, {\"index\": 386, \"accuracy\": 0.6228070175438597}, {\"index\": 387, \"accuracy\": 0.6228070175438597}, {\"index\": 388, \"accuracy\": 0.6228070175438597}, {\"index\": 389, \"accuracy\": 0.6228070175438597}, {\"index\": 390, \"accuracy\": 0.6228070175438597}, {\"index\": 391, \"accuracy\": 0.6228070175438597}, {\"index\": 392, \"accuracy\": 0.6228070175438597}, {\"index\": 393, \"accuracy\": 0.6228070175438597}, {\"index\": 394, \"accuracy\": 0.6228070175438597}, {\"index\": 395, \"accuracy\": 0.6228070175438597}, {\"index\": 396, \"accuracy\": 0.6228070175438597}, {\"index\": 397, \"accuracy\": 0.6228070175438597}, {\"index\": 398, \"accuracy\": 0.6228070175438597}, {\"index\": 399, \"accuracy\": 0.6228070175438597}, {\"index\": 400, \"accuracy\": 0.6228070175438597}, {\"index\": 401, \"accuracy\": 0.6228070175438597}, {\"index\": 402, \"accuracy\": 0.6228070175438597}, {\"index\": 403, \"accuracy\": 0.6228070175438597}, {\"index\": 404, \"accuracy\": 0.6228070175438597}, {\"index\": 405, \"accuracy\": 0.6228070175438597}, {\"index\": 406, \"accuracy\": 0.6228070175438597}, {\"index\": 407, \"accuracy\": 0.6228070175438597}, {\"index\": 408, \"accuracy\": 0.6228070175438597}, {\"index\": 409, \"accuracy\": 0.6228070175438597}, {\"index\": 410, \"accuracy\": 0.6228070175438597}, {\"index\": 411, \"accuracy\": 0.6228070175438597}, {\"index\": 412, \"accuracy\": 0.6228070175438597}, {\"index\": 413, \"accuracy\": 0.6228070175438597}, {\"index\": 414, \"accuracy\": 0.6228070175438597}, {\"index\": 415, \"accuracy\": 0.6228070175438597}, {\"index\": 416, \"accuracy\": 0.6228070175438597}, {\"index\": 417, \"accuracy\": 0.6228070175438597}, {\"index\": 418, \"accuracy\": 0.6228070175438597}, {\"index\": 419, \"accuracy\": 0.6228070175438597}, {\"index\": 420, \"accuracy\": 0.6228070175438597}, {\"index\": 421, \"accuracy\": 0.6228070175438597}, {\"index\": 422, \"accuracy\": 0.6228070175438597}, {\"index\": 423, \"accuracy\": 0.6228070175438597}, {\"index\": 424, \"accuracy\": 0.6228070175438597}, {\"index\": 425, \"accuracy\": 0.6228070175438597}, {\"index\": 426, \"accuracy\": 0.6228070175438597}, {\"index\": 427, \"accuracy\": 0.6228070175438597}, {\"index\": 428, \"accuracy\": 0.6228070175438597}, {\"index\": 429, \"accuracy\": 0.6228070175438597}, {\"index\": 430, \"accuracy\": 0.6228070175438597}, {\"index\": 431, \"accuracy\": 0.6228070175438597}, {\"index\": 432, \"accuracy\": 0.6228070175438597}, {\"index\": 433, \"accuracy\": 0.6228070175438597}, {\"index\": 434, \"accuracy\": 0.6228070175438597}, {\"index\": 435, \"accuracy\": 0.6228070175438597}, {\"index\": 436, \"accuracy\": 0.6228070175438597}, {\"index\": 437, \"accuracy\": 0.6228070175438597}, {\"index\": 438, \"accuracy\": 0.6228070175438597}, {\"index\": 439, \"accuracy\": 0.6228070175438597}, {\"index\": 440, \"accuracy\": 0.6228070175438597}, {\"index\": 441, \"accuracy\": 0.6228070175438597}, {\"index\": 442, \"accuracy\": 0.6228070175438597}, {\"index\": 443, \"accuracy\": 0.6228070175438597}, {\"index\": 444, \"accuracy\": 0.6228070175438597}, {\"index\": 445, \"accuracy\": 0.6228070175438597}, {\"index\": 446, \"accuracy\": 0.6228070175438597}, {\"index\": 447, \"accuracy\": 0.6228070175438597}, {\"index\": 448, \"accuracy\": 0.6228070175438597}, {\"index\": 449, \"accuracy\": 0.6228070175438597}, {\"index\": 450, \"accuracy\": 0.6228070175438597}, {\"index\": 451, \"accuracy\": 0.6228070175438597}, {\"index\": 452, \"accuracy\": 0.6228070175438597}, {\"index\": 453, \"accuracy\": 0.6228070175438597}, {\"index\": 454, \"accuracy\": 0.6228070175438597}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best K to pick is 10 which gives an accuracy of 0.9824561403508771\n"
     ]
    }
   ],
   "source": [
    "# fine-tuning K\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import altair as alt\n",
    "import pandas as pd\n",
    "\n",
    "breast_cancer = load_breast_cancer()\n",
    "X = breast_cancer.data\n",
    "y = breast_cancer.target\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "a = []\n",
    "index = []\n",
    "for i in range(1,len(X_train)):\n",
    "    index.append(i)\n",
    "    # Create and train the KNN classifier\n",
    "    knn_classifier = KNNClassifier(k=i)\n",
    "    knn_classifier.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    predictions = knn_classifier.predict(X_test)\n",
    "    \n",
    "    # Calculate accuracy [1 point for good accuracy]\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    a.append(accuracy)\n",
    "\n",
    "df = pd.DataFrame({'index': index, 'accuracy': a})\n",
    "\n",
    "chart = alt.Chart(df).mark_line().encode(\n",
    "    x=alt.X('index', title='Choice of K'),\n",
    "    y=alt.Y('accuracy', title='Values')\n",
    ").properties(\n",
    "    width=800,\n",
    "    height=500\n",
    ")\n",
    "display(chart)\n",
    "\n",
    "optimal_k = df[df['accuracy'] == df['accuracy'].max()].index.values[0]\n",
    "optimal_accuracy = df['accuracy'].max()\n",
    "print(\"Best K to pick is\", optimal_k, \"which gives an accuracy of\", optimal_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
