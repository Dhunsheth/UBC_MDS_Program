<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

The objective of the assignment is to learn about hyperparameter tuning using copilot-generated code. To use copilot, open Ms Edge (or your preferred browser; MS recommends edge not surprisingly) and go to <a href="https://www.bing.com/search?q=Bing+AI&showconv=1">https://www.bing.com/search?q=Bing+AI&showconv=1</a>.

<h1>Copilot starting point</h1>
Ask the following question to Copilot:
<p>Q: Write a tutorial on hyperparameter optimization for a neural network; include all Python code to go through each step. The tutorial must demonstrate random search, grid search, and 2 other optimization methods. The hyperparameters to consider are: the number of hidden layers, the activation function, the solver selected, and the learning rate. You may add other hyperparameters, but the training must be fairly quick.

Modify the code so it works and returns the accuracy with the hyperparameter values. 


<h1>Submission</h1>
Report your findings as 
<ol>
<li>your code with the output it generates,
<li>an explanation on what you had to modify to make the code work,
<li>a reflection on copilot: did you save time by asking copilot? Were there any error in the answers? Would you use copilot in the future?
</ol>
Submit all 3 files: ho.py, fixes.txt, and reflection.txt.