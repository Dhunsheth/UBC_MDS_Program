log_product[log_product != 0]
predictors_pca <- as.data.frame(pca_cars$x[, 1:2])
response <- data$Type
lda_cars <- lda(response ~ ., data = data.frame(response = response, predictors_pca), CV = TRUE)
y_1 <- ifelse(response == 'Compact', 1, 0)
y_2 <- ifelse(response == 'Large', 1, 0)
y_3 <- ifelse(response == 'Midsize', 1, 0)
y_4 <- ifelse(response == 'Small', 1, 0)
y_5 <- ifelse(response == 'Sporty', 1, 0)
y <- cbind(y_1, y_2, y_3, y_4, y_5)
log_product <- y * log(lda_cars$posterior)
log_loss <- -mean(log_product[log_product != 0])
print(log_loss)
knitr::opts_chunk$set(echo = TRUE)
library(MASS)
library(mclust)
library(ggplot2)
data <- read.csv('car93.csv')
pca_cars <- prcomp(data[,-1:-3], scale.=TRUE)
print(summary(pca_cars))
biplot(pca_cars)
print(pca_cars$rotation[,1:2])
print(summary(pca_cars))
plot(pca_cars, type="lines")
predictors_pca <- as.data.frame(pca_cars$x[, 1:2])
response <- ifelse(data$Type == "Small", "Small", "Not Small")
lda_cars <- lda(response ~ ., data = data.frame(response = response, predictors_pca), CV = TRUE)
y_1 <- ifelse(response == 'Not Small', 1, 0)
y_2 <- ifelse(response == 'Small', 1, 0)
y <- cbind(y_1, y_2)
log_product <- y * log(lda_cars$posterior)
log_loss <- -mean(log_product[log_product != 0])
print(log_loss)
predictors_pca <- as.data.frame(pca_cars$x[, 1:2])
response <- data$Type
lda_cars <- lda(response ~ ., data = data.frame(response = response, predictors_pca), CV = TRUE)
y_1 <- ifelse(response == 'Compact', 1, 0)
y_2 <- ifelse(response == 'Large', 1, 0)
y_3 <- ifelse(response == 'Midsize', 1, 0)
y_4 <- ifelse(response == 'Small', 1, 0)
y_5 <- ifelse(response == 'Sporty', 1, 0)
y <- cbind(y_1, y_2, y_3, y_4, y_5)
log_product <- y * log(lda_cars$posterior)
log_loss <- -mean(log_product[log_product != 0])
print(log_loss)
data <- banknote
print(summary(data[,-1:-2]))
print(cor(data[,-1:-2]))
scaled_data <- scale(data[,-1:-2])
dist_matrix <- dist(scaled_data, method = "euclidean")
hc_single <- hclust(dist_matrix, method = "single")
hc_complete <- hclust(dist_matrix, method = "complete")
hc_avg <- hclust(dist_matrix, method = "average")
plot(hc_single, hang = -1, labels = rownames(data))
plot(hc_complete, hang = -1, labels = rownames(data))
plot(hc_avg, hang = -1, labels = rownames(data))
clusters <- cutree(hc_complete, k=2)
# data$cluster <- as.factor(clusters)
conf_matrix <- table(data$Status, clusters)
print(conf_matrix)
misclassification_rate <- 1 - sum(diag(conf_matrix)) / sum(conf_matrix)
print(misclassification_rate)
set.seed(632)
k_means <- kmeans(scaled_data, 2, nstart=25)
conf_matrix <- table(data$Status, k_means$cluster)
print(conf_matrix)
misclassification_rate <- 1 - sum(diag(conf_matrix)) / sum(conf_matrix)
print(misclassification_rate)
set.seed(632)
k_means <- kmeans(data[,-1:-2], 2, nstart=25)
conf_matrix <- table(data$Status, k_means$cluster)
print(conf_matrix)
misclassification_rate <- 1 - sum(diag(conf_matrix)) / sum(conf_matrix)
print(misclassification_rate)
opposite_diagonal <- conf_matrix[cbind(num_rows:1, num_cols:1)]
opposite_diagonal <- conf_matrix[cbind(nrow(conf_matrix):1, ncol(conf_matrix):1)]
opposite_diagonal
diag(conf_matrix)
n <- nrow(conf_matrix)
opposite_diag_values <- conf_matrix[cbind(n:1, 1:n)]
opposite_diag_values
sum(opposite_diag_values)
set.seed(632)
k_means <- kmeans(data[,-1:-2], 2, nstart=25)
conf_matrix <- table(data$Status, k_means$cluster)
print(conf_matrix)
n <- nrow(conf_matrix)
opposite_diag_values <- conf_matrix[cbind(n:1, 1:n)]
misclassification_rate <- 1 - sum(opposite_diag_values) / sum(conf_matrix)
print(misclassification_rate)
a <- load('bsim.Rdata')
data <- data.frame(asim)
# initial data exploration
plot(data)
print(cor(data[,-1]))
print(cov(data[,-1]))
# initial linear model
initial_linear <- lm(y ~. , data=data)
print(summary(initial_linear))
# PCA
pca_data <- prcomp(data[,-1], scale.=TRUE)
print(biplot(pca_data))
print(summary(pca_data))
pca_predictors <- as.data.frame(pca_data$x[, 1:2])
pca_predictors <- data.frame(data[,1], pca_predictors)
colnames(pca_predictors)[colnames(pca_predictors) == 'data...1.'] <- 'y'
linear <- lm(y ~., data=pca_predictors)
summary(linear)
# Clustering
# scaled_data <- scale(data[,-1], scale=TRUE)
# dist_matrix <- dist(scaled_data, method = "euclidean") #
# hc_single <- hclust(dist_matrix, method = "single")
# hc_complete <- hclust(dist_matrix, method = "complete")
# hc_avg <- hclust(dist_matrix, method = "average")
#
# plot(hc_single, hang = -1, labels = rownames(data))
# plot(hc_complete, hang = -1, labels = rownames(data))
# plot(hc_avg, hang = -1, labels = rownames(data))
#
# k_means <- kmeans(data[,-1], 2, nstart=1000)
a <- load('bsim.Rdata')
data <- data.frame(asim)
# initial data exploration
plot(data)
print(cor(data[,-1]))
print(cov(data[,-1]))
# initial linear model
initial_linear <- lm(y ~. , data=data)
print(summary(initial_linear))
# PCA
pca_data <- prcomp(data[,-1], scale.=TRUE)
print(biplot(pca_data))
print(summary(pca_data))
pca_predictors <- as.data.frame(pca_data$x[, 1:2])
pca_predictors <- data.frame(data[,1], pca_predictors)
colnames(pca_predictors)[colnames(pca_predictors) == 'data...1.'] <- 'y'
linear <- lm(y ~., data=pca_predictors)
summary(linear)
# Clustering
# scaled_data <- scale(data[,-1], scale=TRUE)
# dist_matrix <- dist(scaled_data, method = "euclidean") #
# hc_single <- hclust(dist_matrix, method = "single")
# hc_complete <- hclust(dist_matrix, method = "complete")
# hc_avg <- hclust(dist_matrix, method = "average")
#
# plot(hc_single, hang = -1, labels = rownames(data))
# plot(hc_complete, hang = -1, labels = rownames(data))
# plot(hc_avg, hang = -1, labels = rownames(data))
#
k_means <- kmeans(data[,-1], 2, nstart=1000)
k_means
k_means$cluster
a <- load('bsim.Rdata')
data <- data.frame(asim)
# initial data exploration
plot(data)
print(cor(data[,-1]))
print(cov(data[,-1]))
# initial linear model
initial_linear <- lm(y ~. , data=data)
print(summary(initial_linear))
# PCA
pca_data <- prcomp(data[,-1], scale.=TRUE)
print(biplot(pca_data))
print(summary(pca_data))
pca_predictors <- as.data.frame(pca_data$x[, 1:2])
pca_predictors <- data.frame(data[,1], pca_predictors)
colnames(pca_predictors)[colnames(pca_predictors) == 'data...1.'] <- 'y'
linear <- lm(y ~., data=pca_predictors)
summary(linear)
# Clustering
# scaled_data <- scale(data[,-1], scale=TRUE)
# dist_matrix <- dist(scaled_data, method = "euclidean") #
# hc_single <- hclust(dist_matrix, method = "single")
# hc_complete <- hclust(dist_matrix, method = "complete")
# hc_avg <- hclust(dist_matrix, method = "average")
#
# plot(hc_single, hang = -1, labels = rownames(data))
# plot(hc_complete, hang = -1, labels = rownames(data))
# plot(hc_avg, hang = -1, labels = rownames(data))
#
k_means <- kmeans(data[,-1], 2, nstart=1000)
temp_data <- data
temp_data$cluster <- k_means$cluster
l <- lm(y ~. , data=temp_data)
print(summary(l))
summary(l)
k_means$cluster
temp_data
scale_data <- scale(data)
scale_data
scale_data <- scale(data)
initial_linear <- lm(y ~. , data=scale_data)
scale_data <- data.frame(scale(data))
scale_data
scale_data <- data.frame(scale(data))
initial_linear <- lm(y ~. , data=scale_data)
print(summary(initial_linear))
pca_predictors
scale_data
a <- load('bsim.Rdata')
data <- data.frame(asim)
# initial data exploration
plot(data)
print(cor(data[,-1]))
print(cov(data[,-1]))
# initial linear model
initial_linear <- lm(y ~. , data=data)
print(summary(initial_linear))
# PCA
pca_data <- prcomp(data[,-1], scale.=TRUE)
print(biplot(pca_data))
print(summary(pca_data))
pca_predictors <- as.data.frame(pca_data$x[, 1:2])
pca_predictors <- data.frame(data[,1], pca_predictors)
colnames(pca_predictors)[colnames(pca_predictors) == 'data...1.'] <- 'y'
linear <- lm(y ~., data=pca_predictors)
summary(linear)
# Clustering
# scaled_data <- scale(data[,-1], scale=TRUE)
# dist_matrix <- dist(scaled_data, method = "euclidean") #
# hc_single <- hclust(dist_matrix, method = "single")
# hc_complete <- hclust(dist_matrix, method = "complete")
# hc_avg <- hclust(dist_matrix, method = "average")
#
# plot(hc_single, hang = -1, labels = rownames(data))
# plot(hc_complete, hang = -1, labels = rownames(data))
# plot(hc_avg, hang = -1, labels = rownames(data))
#
k_means <- kmeans(data[,-1], 2, nstart=1000)
temp_data <- data
temp_data$cluster <- k_means$cluster
l <- lm(y ~. , data=temp_data)
print(summary(l))
temp_data <- data
temp_data$cluster <- k_means$cluster
l <- lm(y ~ cluster*(V2+V3+V4+V5+V6+V7+V8+V9+V10) , data=temp_data)
print(summary(l))
knitr::opts_chunk$set(echo = TRUE)
library(MASS)
library(mclust)
library(ggplot2)
data <- read.csv('car93.csv')
pca_cars <- prcomp(data[,-1:-3], scale.=TRUE)
print(summary(pca_cars))
biplot(pca_cars)
print(pca_cars$rotation[,1:2])
print(summary(pca_cars))
plot(pca_cars, type="lines")
log_product
log_product[log_product != 0]
lda_cars$posterior
knitr::opts_chunk$set(echo = TRUE)
library(MASS)
library(mclust)
library(ggplot2)
data <- read.csv('car93.csv')
pca_cars <- prcomp(data[,-1:-3], scale.=TRUE)
print(summary(pca_cars))
biplot(pca_cars)
print(pca_cars$rotation[,1:2])
print(summary(pca_cars))
plot(pca_cars, type="lines")
predictors_pca <- as.data.frame(pca_cars$x[, 1:2])
response <- ifelse(data$Type == "Small", "Small", "Not Small")
lda_cars <- lda(response ~ ., data = data.frame(response = response, predictors_pca), CV = TRUE)
y_1 <- ifelse(response == 'Not Small', 1, 0)
y_2 <- ifelse(response == 'Small', 1, 0)
y <- cbind(y_1, y_2)
log_product <- y * log(lda_cars$posterior)
log_loss <- -mean(log_product[log_product != 0])
print(log_loss)
predictors_pca <- as.data.frame(pca_cars$x[, 1:2])
response <- data$Type
lda_cars <- lda(response ~ ., data = data.frame(response = response, predictors_pca), CV = TRUE)
y_1 <- ifelse(response == 'Compact', 1, 0)
y_2 <- ifelse(response == 'Large', 1, 0)
y_3 <- ifelse(response == 'Midsize', 1, 0)
y_4 <- ifelse(response == 'Small', 1, 0)
y_5 <- ifelse(response == 'Sporty', 1, 0)
y <- cbind(y_1, y_2, y_3, y_4, y_5)
log_product <- y * log(lda_cars$posterior)
log_loss <- -mean(log_product[log_product != 0])
print(log_loss)
data <- banknote
print(summary(data[,-1:-2]))
print(cor(data[,-1:-2]))
scaled_data <- scale(data[,-1:-2])
dist_matrix <- dist(scaled_data, method = "euclidean")
hc_single <- hclust(dist_matrix, method = "single")
hc_complete <- hclust(dist_matrix, method = "complete")
hc_avg <- hclust(dist_matrix, method = "average")
plot(hc_single, hang = -1, labels = rownames(data))
plot(hc_complete, hang = -1, labels = rownames(data))
plot(hc_avg, hang = -1, labels = rownames(data))
clusters <- cutree(hc_complete, k=2)
# data$cluster <- as.factor(clusters)
conf_matrix <- table(data$Status, clusters)
print(conf_matrix)
misclassification_rate <- 1 - sum(diag(conf_matrix)) / sum(conf_matrix)
print(misclassification_rate)
set.seed(632)
k_means <- kmeans(scaled_data, 2, nstart=25)
conf_matrix <- table(data$Status, k_means$cluster)
print(conf_matrix)
misclassification_rate <- 1 - sum(diag(conf_matrix)) / sum(conf_matrix)
print(misclassification_rate)
set.seed(632)
k_means <- kmeans(data[,-1:-2], 2, nstart=25)
conf_matrix <- table(data$Status, k_means$cluster)
print(conf_matrix)
n <- nrow(conf_matrix)
opposite_diag_values <- conf_matrix[cbind(n:1, 1:n)]
misclassification_rate <- 1 - sum(opposite_diag_values) / sum(conf_matrix)
print(misclassification_rate)
load("lots.Rdata")
data <- data.frame(datmat)
data$clusts <- as.factor(clusts)
plot <- ggplot(data, aes(x=X1, y=X2, color=clusts)) +
geom_point()
print(plot)
set.seed(1026)
k_means <- kmeans(data[,-3], 20)
adj_rand_index <- adjustedRandIndex(as.numeric(data$clusts), as.numeric(k_means$cluster))
print(adj_rand_index)
set.seed(6201)
k_means <- kmeans(data[,-3], 20)
adj_rand_index <- adjustedRandIndex(as.numeric(data$clusts), as.numeric(k_means$cluster))
print(adj_rand_index)
set.seed(1026)
k_means <- kmeans(data[,-3], 20, nstart=1000)
adj_rand_index <- adjustedRandIndex(as.numeric(data$clusts), as.numeric(k_means$cluster))
print(adj_rand_index)
set.seed(6201)
k_means <- kmeans(data[,-3], 20, nstart=1000)
adj_rand_index <- adjustedRandIndex(as.numeric(data$clusts), as.numeric(k_means$cluster))
print(adj_rand_index)
scaled_data
a <- load('bsim.Rdata')
data <- data.frame(asim)
# initial data exploration
plot(data)
print(cor(data[,-1]))
print(cov(data[,-1]))
# initial linear model
initial_linear <- lm(y ~. , data=data)
print(summary(initial_linear))
# PCA
pca_data <- prcomp(data[,-1], scale.=TRUE)
print(biplot(pca_data))
print(summary(pca_data))
pca_predictors <- as.data.frame(pca_data$x[, 1:2])
pca_predictors <- data.frame(data[,1], pca_predictors)
colnames(pca_predictors)[colnames(pca_predictors) == 'data...1.'] <- 'y'
linear <- lm(y ~., data=pca_predictors)
summary(linear)
# Clustering
scaled_data <- scale(data[,-1], scale=TRUE)
# Decide to go with 2 groups
k_means <- kmeans(data[,-1], 2, nstart=1000)
temp_data <- data
temp_data$cluster <- k_means$cluster
l <- lm(y ~ cluster*(V2+V3+V4+V5+V6+V7+V8+V9+V10) , data=temp_data)
print(summary(l))
scaled_data
a <- load('bsim.Rdata')
data <- data.frame(asim)
# initial data exploration
plot(data)
print(cor(data[,-1]))
print(cov(data[,-1]))
# initial linear model
initial_linear <- lm(y ~. , data=data)
print(summary(initial_linear))
# PCA
pca_data <- prcomp(data[,-1], scale.=TRUE)
print(biplot(pca_data))
print(summary(pca_data))
pca_predictors <- as.data.frame(pca_data$x[, 1:2])
pca_predictors <- data.frame(data[,1], pca_predictors)
colnames(pca_predictors)[colnames(pca_predictors) == 'data...1.'] <- 'y'
linear <- lm(y ~., data=pca_predictors)
summary(linear)
# Clustering
scaled_data <- scale(data[,-1], scale=TRUE)
# Decide to go with 2 groups
k_means <- kmeans(scaled_data, 2, nstart=1000)
temp_data <- scaled_data
temp_data$cluster <- k_means$cluster
l <- lm(y ~ cluster*(V2+V3+V4+V5+V6+V7+V8+V9+V10) , data=temp_data)
temp_data
k_means
# Clustering
scaled_data <- data.frame(scale(data[,-1], scale=TRUE))
a <- load('bsim.Rdata')
data <- data.frame(asim)
# initial data exploration
plot(data)
print(cor(data[,-1]))
print(cov(data[,-1]))
# initial linear model
initial_linear <- lm(y ~. , data=data)
print(summary(initial_linear))
# PCA
pca_data <- prcomp(data[,-1], scale.=TRUE)
print(biplot(pca_data))
print(summary(pca_data))
pca_predictors <- as.data.frame(pca_data$x[, 1:2])
pca_predictors <- data.frame(data[,1], pca_predictors)
colnames(pca_predictors)[colnames(pca_predictors) == 'data...1.'] <- 'y'
linear <- lm(y ~., data=pca_predictors)
summary(linear)
# Clustering
scaled_data <- data.frame(scale(data[,-1], scale=TRUE))
# Decide to go with 2 groups
k_means <- kmeans(scaled_data, 2, nstart=1000)
temp_data <- scaled_data
temp_data$cluster <- k_means$cluster
l <- lm(y ~ cluster*(V2+V3+V4+V5+V6+V7+V8+V9+V10) , data=temp_data)
temp_data
a <- load('bsim.Rdata')
data <- data.frame(asim)
# initial data exploration
plot(data)
print(cor(data[,-1]))
print(cov(data[,-1]))
# initial linear model
initial_linear <- lm(y ~. , data=data)
print(summary(initial_linear))
# PCA
pca_data <- prcomp(data[,-1], scale.=TRUE)
print(biplot(pca_data))
print(summary(pca_data))
pca_predictors <- as.data.frame(pca_data$x[, 1:2])
pca_predictors <- data.frame(data[,1], pca_predictors)
colnames(pca_predictors)[colnames(pca_predictors) == 'data...1.'] <- 'y'
linear <- lm(y ~., data=pca_predictors)
summary(linear)
# Clustering
scaled_data <- data.frame(scale(data[,-1], scale=TRUE))
# Decide to go with 2 groups
k_means <- kmeans(scaled_data, 2, nstart=1000)
temp_data <- data
temp_data$cluster <- k_means$cluster
l <- lm(y ~ cluster*(V2+V3+V4+V5+V6+V7+V8+V9+V10) , data=temp_data)
print(summary(l))
data <- data.frame(datmat)
data
summary(data)
set.seed(1026)
scaled_data <- scale(data)
k_means <- kmeans(scaled_data[,-3], 20)
adj_rand_index <- adjustedRandIndex(as.numeric(data$clusts), as.numeric(k_means$cluster))
k_means
k_means$cluster
load("lots.Rdata")
data <- data.frame(datmat)
data$clusts <- as.factor(clusts)
plot <- ggplot(data, aes(x=X1, y=X2, color=clusts)) +
geom_point()
print(plot)
set.seed(1026)
scaled_data <- scale(data)
data
load("lots.Rdata")
data <- data.frame(datmat)
data <- data.frame(scale(data))
data$clusts <- as.factor(clusts)
plot <- ggplot(data, aes(x=X1, y=X2, color=clusts)) +
geom_point()
print(plot)
load("lots.Rdata")
data <- data.frame(datmat)
data$clusts <- as.factor(clusts)
plot <- ggplot(data, aes(x=X1, y=X2, color=clusts)) +
geom_point()
print(plot)
set.seed(1026)
scaled_data <- scale(data[,-3])
k_means <- kmeans(scaled_data, 20)
adj_rand_index <- adjustedRandIndex(as.numeric(data$clusts), as.numeric(k_means$cluster))
print(adj_rand_index)
load("lots.Rdata")
data <- data.frame(datmat)
data$clusts <- as.factor(clusts)
plot <- ggplot(data, aes(x=X1, y=X2, color=clusts)) +
geom_point()
print(plot)
set.seed(1026)
scaled_data <- scale(data[,-3])
k_means <- kmeans(scaled_data, 20)
adj_rand_index <- adjustedRandIndex(as.numeric(data$clusts), as.numeric(k_means$cluster))
print(adj_rand_index)
set.seed(6201)
scaled_data <- scale(data[,-3])
k_means <- kmeans(scaled_data, 20)
adj_rand_index <- adjustedRandIndex(as.numeric(data$clusts), as.numeric(k_means$cluster))
print(adj_rand_index)
set.seed(1026)
scaled_data <- scale(data[,-3])
k_means <- kmeans(scaled_data, 20, nstart=1000)
adj_rand_index <- adjustedRandIndex(as.numeric(data$clusts), as.numeric(k_means$cluster))
print(adj_rand_index)
set.seed(6201)
scaled_data <- scale(data[,-3])
k_means <- kmeans(scale_data, 20, nstart=1000)
adj_rand_index <- adjustedRandIndex(as.numeric(data$clusts), as.numeric(k_means$cluster))
set.seed(6201)
scaled_data <- scale(data[,-3])
k_means <- kmeans(scaled_data, 20, nstart=1000)
adj_rand_index <- adjustedRandIndex(as.numeric(data$clusts), as.numeric(k_means$cluster))
print(adj_rand_index)
